{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3A.mr - 2015 - Factorisation de matrice avec PIG\n",
        "\n",
        "Ce travail s'appuie sur l'article [A Fast Distributed Stochastic Gradient Descent Algorithm for Matrix Factorization](http://www.jmlr.org/proceedings/papers/v36/li14.html), Fanglin Li, BinWu, Liutong Xu, Chuan Shi, and Jing Shi. Auteurs : *Th\u00e9o Gantzer, Anna Korba*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connexion au cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"background-color:gainsboro; padding:2px; border:0px;\"><b>server + hadoop + credentials</b>\n",
              "<br />blob_storage <input type=\"text\" id=\"blobhpblob_storage\" value=\"\" size=\"80\" />\n",
              "<br />hadoop_server <input type=\"text\" id=\"blobhphadoop_server\" value=\"\" size=\"80\" />\n",
              "<br />password1 <input type=\"password\" id=\"blobhppassword1\" value=\"\" size=\"80\" />\n",
              "<br />password2 <input type=\"password\" id=\"blobhppassword2\" value=\"\" size=\"80\" />\n",
              "<br />username <input type=\"text\" id=\"blobhpusername\" value=\"alias\" size=\"80\" />\n",
              "<br /><button onclick=\"set_valueblobhp()\">Ok</button></div>\n",
              "<script type=\"text/Javascript\">\n",
              "function blobhpcallback(msg) {\n",
              "   var ret = msg.content.data['text/plain'];\n",
              "   $('#outblobhp').text(ret);\n",
              "}\n",
              "function set_valueblobhp(){\n",
              "   command='blobhp = {' ;\n",
              "   var blobhpblob_storagevar_value = document.getElementById('blobhpblob_storage').value;\n",
              "   command += '\"blob_storage\":\"' + blobhpblob_storagevar_value + '\",';\n",
              "   var blobhphadoop_servervar_value = document.getElementById('blobhphadoop_server').value;\n",
              "   command += '\"hadoop_server\":\"' + blobhphadoop_servervar_value + '\",';\n",
              "   var blobhppassword1var_value = document.getElementById('blobhppassword1').value;\n",
              "   command += '\"password1\":\"' + blobhppassword1var_value + '\",';\n",
              "   var blobhppassword2var_value = document.getElementById('blobhppassword2').value;\n",
              "   command += '\"password2\":\"' + blobhppassword2var_value + '\",';\n",
              "   var blobhpusernamevar_value = document.getElementById('blobhpusername').value;\n",
              "   command += '\"username\":\"' + blobhpusernamevar_value + '\",';\n",
              "   command += '}';\n",
              "   var kernel = IPython.notebook.kernel;\n",
              "   kernel.execute(command);\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pyquickhelper, pyensae\n",
        "params={\"blob_storage\":\"\", \"password1\":\"\", \"hadoop_server\":\"\", \"password2\":\"\", \"username\":\"alias\"}\n",
        "pyquickhelper.ipythonhelper.open_html_form(params=params,title=\"server + hadoop + credentials\", key_save=\"blobhp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xaviermf\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(<pyensae.remote.azure_connection.AzureClient at 0x8c2b2b0>,\n",
              " <azure.storage.blobservice.BlobService at 0x8c2bf98>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pyensae\n",
        "%load_ext pyensae\n",
        "%load_ext pyenbc\n",
        "blobstorage = blobhp[\"blob_storage\"]\n",
        "blobpassword = blobhp[\"password1\"]\n",
        "hadoop_server = blobhp[\"hadoop_server\"]\n",
        "hadoop_password = blobhp[\"password2\"]\n",
        "username = blobhp[\"username\"]\n",
        "print(username)\n",
        "client, bs =  %hd_open\n",
        "client, bs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [name, url]\n",
              "Index: []"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%blob_ls /$PSEUDO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### T\u00e9l\u00e9chargment des donn\u00e9es et transfert sur le cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    downloading of  http://files.grouplens.org/datasets/movielens/ml-1m.zip  to  ml-1m.zip\n",
            "    creating folder  .\\ml-1m\n",
            "    unzipped  ml-1m/movies.dat  to  .\\ml-1m/movies.dat\n",
            "    unzipped  ml-1m/ratings.dat  to  .\\ml-1m/ratings.dat\n",
            "    unzipped  ml-1m/README  to  .\\ml-1m/README\n",
            "    unzipped  ml-1m/users.dat  to  .\\ml-1m/users.dat\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['.\\\\ml-1m/movies.dat',\n",
              " '.\\\\ml-1m/ratings.dat',\n",
              " '.\\\\ml-1m/README',\n",
              " '.\\\\ml-1m/users.dat']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pyensae.datasource\n",
        "url = \"http://files.grouplens.org/datasets/movielens/\"\n",
        "file = \"ml-1m.zip\"\n",
        "pyensae.datasource.download_data(file, website=url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ml-1m', 'ml-1m.zip']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pyensae\n",
        "[ _ for _ in os.listdir() if \"ml\" in _ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Ici on charge les donn\u00e9es puis on les stocke dans un dictionnaire\n",
        "from itertools import islice\n",
        "\n",
        "lines = np.genfromtxt('ml-1m/ratings.dat', delimiter=\"::\", dtype=None)\n",
        "my_dict = dict()\n",
        "for i in range(len(lines)):\n",
        "   my_dict[lines[i][0],lines[i][1]] = lines[i][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[((822, 1620), 4), ((2488, 1459), 3), ((3389, 423), 2), ((4305, 508), 4), ((1163, 3752), 3), ((2895, 3070), 5), ((3780, 2916), 5), ((3308, 185), 3), ((3029, 296), 5), ((1151, 1265), 4)]\n"
          ]
        }
      ],
      "source": [
        "# Nous avons ((userID, movieID), rating)\n",
        "\n",
        "def take(n, iterable): \n",
        "     return list(islice(iterable,n))\n",
        "print(take(10, my_dict.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 822 1620    4]\n",
            " [2488 1459    3]\n",
            " [3389  423    2]\n",
            " ..., \n",
            " [2628 2240    2]\n",
            " [5762 2085    4]\n",
            " [2895 3173    3]]\n"
          ]
        }
      ],
      "source": [
        "### ICI on cr\u00e9e la matrice sparse R des ratings\n",
        "\n",
        "import json\n",
        "from pandas import Series,DataFrame\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "data = []\n",
        "row = []\n",
        "col = []\n",
        "for k, v in my_dict.items():\n",
        "    k=np.asarray(k)\n",
        "    r = int(k[0])\n",
        "    c = int(k[1])\n",
        "    data.append(v)\n",
        "    row.append(r)\n",
        "    col.append(c)\n",
        "R = sparse.coo_matrix((data,(row,col)))\n",
        "\n",
        "\n",
        "# Et on la met sous forme de trois colonnes indice_ligne, indice_colonne, valeur\n",
        "\n",
        "data=np.array([R.row, R.col, R.data])\n",
        "data=np.transpose(data)\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Attention il faut executer cette fen\u00eatre deux fois (la premiere fois une erreur appara\u00eet)\n",
        "\n",
        "# Ici on cr\u00e9\u00e9 les matrices P et Q dont le produit doit approximer R.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', header = None,sep=\"::\",engine=\"python\")\n",
        "ratings.columns=['user_id','item_id', 'rating', 'timestamp']\n",
        "ratings=ratings[['user_id','item_id', 'rating']]\n",
        "#Series(df.values.ravel()).unique()\n",
        "m=len(Series(ratings['user_id'].values.ravel()).unique()) #m nb d'users\n",
        "n=len(Series(ratings['item_id'].values.ravel()).unique()) #n nb d'items\n",
        "\n",
        "# Nous les codons de la m\u00eame mani\u00e8re que data, c'est-\u00e0-dire sous forme de trois colonnes.\n",
        "# Ces matrices sont initialis\u00e9es avec des nombres al\u00e9atoires entre 0 et 1.\n",
        "\n",
        "d=10 # dimension latente\n",
        "\n",
        "# P est de dimension m*d\n",
        "\n",
        "p=np.random.uniform(0,1,((m*d)))\n",
        "row_p=[x for x in Series(ratings['user_id'].values.ravel()).unique() for j in range(0,10)]\n",
        "col_int=[  i for j in range(0,m) for i in range(1,11) ]\n",
        "P = sparse.coo_matrix((p,(row_p,col_int)))\n",
        "matrix_p=np.array([P.row, P.col, P.data])\n",
        "matrix_p=np.transpose(matrix_p)\n",
        "\n",
        "# q est de dimension n*d\n",
        "\n",
        "q=np.random.uniform(0,1,((n*d)))\n",
        "row_q=[x for x in Series(ratings['item_id'].values.ravel()).unique() for j in range(0,10)]\n",
        "col_int=[ i for j in range(0,n) for i in range(1,11)]\n",
        "Q = sparse.coo_matrix((q,(row_q,col_int)))\n",
        "matrix_q=np.array([Q.row, Q.col, Q.data])\n",
        "matrix_q=np.transpose(matrix_q)\n",
        "\n",
        "np.savetxt(\"sparse_matrix.csv\", data, delimiter=\",\")\n",
        "np.savetxt(\"matrix_p.csv\", matrix_p, delimiter=\",\")\n",
        "np.savetxt(\"matrix_q.csv\", matrix_q, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'$PSEUDO/projet_DM/data_full.csv'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%blob_up sparse_matrix.csv /$PSEUDO/projet_DM/data_full.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'$PSEUDO/projet_DM/matrix_p_full.csv'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%blob_up matrix_p.csv /$PSEUDO/projet_DM/matrix_p_full.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'$PSEUDO/projet_DM/matrix_q_full.csv'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%blob_up matrix_q.csv /$PSEUDO/projet_DM/matrix_q_full.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>last_modified</th>\n",
              "      <th>content_type</th>\n",
              "      <th>content_length</th>\n",
              "      <th>blob_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xaviermf/projet_DM/data_full.csv</td>\n",
              "      <td>Wed, 15 Jul 2015 22:55:22 GMT</td>\n",
              "      <td>application/octet-stream</td>\n",
              "      <td>75015675</td>\n",
              "      <td>BlockBlob</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xaviermf/projet_DM/matrix_p_full.csv</td>\n",
              "      <td>Wed, 15 Jul 2015 22:56:19 GMT</td>\n",
              "      <td>application/octet-stream</td>\n",
              "      <td>4530000</td>\n",
              "      <td>BlockBlob</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xaviermf/projet_DM/matrix_q_full.csv</td>\n",
              "      <td>Wed, 15 Jul 2015 22:56:52 GMT</td>\n",
              "      <td>application/octet-stream</td>\n",
              "      <td>2779500</td>\n",
              "      <td>BlockBlob</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   name                  last_modified  \\\n",
              "0      xaviermf/projet_DM/data_full.csv  Wed, 15 Jul 2015 22:55:22 GMT   \n",
              "1  xaviermf/projet_DM/matrix_p_full.csv  Wed, 15 Jul 2015 22:56:19 GMT   \n",
              "2  xaviermf/projet_DM/matrix_q_full.csv  Wed, 15 Jul 2015 22:56:52 GMT   \n",
              "\n",
              "               content_type  content_length  blob_type  \n",
              "0  application/octet-stream        75015675  BlockBlob  \n",
              "1  application/octet-stream         4530000  BlockBlob  \n",
              "2  application/octet-stream         2779500  BlockBlob  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%blob_ls /$PSEUDO/projet_DM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Impl\u00e9mentation python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def matrix_factorization (R, P, Q, K, steps =100 , gamma =0.02 , lambd =0.02) :\n",
        "    Q = Q.T\n",
        "    # update des matrices P et Q\n",
        "    for step in range ( steps ):\n",
        "        for i in range (len (R)):\n",
        "            for j in range (len(R[i])):\n",
        "                if R[i][j] > 0:\n",
        "                    eij = R[i][j] - np.dot (P[i ,:] ,Q[:,j])\n",
        "                    for k in range (K):\n",
        "                        P[i][k] = P[i][k] + gamma * (2 * eij * Q[k][j] - lambd * P[i][k])\n",
        "                        Q[k][j] = Q[k][j] + gamma * (2 * eij * P[i][k] - lambd * Q[k][j])\n",
        "        eR = np.dot (P,Q)\n",
        "        e = 0\n",
        "        # calcul de la fonction de cout\n",
        "        for i in range (len (R)):\n",
        "            for j in range (len(R[i])):\n",
        "                if R[i][j] > 0:\n",
        "                    e = e + pow (R[i][j] - np.dot(P[i ,:] ,Q[:,j]) , 2)\n",
        "                    for k in range (K):\n",
        "                        e = e + ( lambd /2) * ( pow(P[i][k] ,2) + pow (Q[k][j] ,2) )\n",
        "        if e < 0.001:\n",
        "            break\n",
        "    return P, Q.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normalement, comme le d\u00e9crit le code python ci-dessous, pour r\u00e9aliser la mise \u00e0 jour de $p_{ik}$ on\n",
        "doit se d\u00e9placer sur l'ensemble des colonnes $j$ de $Q$ : en effet, \u00e0 $j$ fix\u00e9, il faut mettre \u00e0 jour $p_{ik}$ en\n",
        "ajoutant la contribution du coefficient $q_{kj}$ \u00e0 l'erreur ; la prochaine fois que $p_{ik}$ sera modifi\u00e9, c'est\n",
        "lorsque l'on sera pass\u00e9 \u00e0 la colonne suivante $j+1$ et que l'on ajoutera la contribution du coefficient\n",
        "$q_{k,j+1}$ \u00e0 l'erreur. Cette modification \u00e0 trois boucles sur $i$, $j$, $k$ \u00e0 \u00e9t\u00e9 pour nous un vrai-casse t\u00eate\n",
        "\u00e0 impl\u00e9menter en PIG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons finalement choisi de mettre \u00e0 jour $P$ puis $Q$. Pour ce faire, nous avons d'abord calcul\u00e9 tous les termes \n",
        "$\\gamma e_{ij}q_{kj}$ puis les nouvelles valeurs d'une mani\u00e8re plus simple : $p_{ik} = p_{ik}(1-\\lambda\\gamma) + \\sum_{j=1}^n \\gamma e_{ij}q_{kj}$. De la m\u00eame mani\u00e8re, nous avons mis \u00e0 jour $Q$ avec les coefficients de $P$ mis \u00e0 jour. Nous sommes conscients que cette fa\u00e7on de modifier les coefficients n'est pas \u00e9quivalente \u00e0 la premi\u00e8re mais c'est la meilleure solution que nous ayons trouv\u00e9e. Pour nos exp\u00e9riences, nous avons d'abord test\u00e9 notre code sur les 100 premi\u00e8res lignes de la base de donn\u00e9es, qui contiennent les notes de 2 utilisateurs sur 99 films, et avons regard\u00e9 la distance euclidienne qui s\u00e9pare $R$ et $PQ$ sur trois it\u00e9rations (les calculs \u00e9taient d\u00e9j\u00e0 relativement lents)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lors de l'impl\u00e9mentation de cette m\u00e9thode en Pig, nous nous sommes aper\u00e7us d'une divergence du produit $PQ$ par rapport \u00e0 la matrice $R$ : la somme des coefficients au carr\u00e9 de $R-PQ$ \u00e9tait de 418 apr\u00e8s initialisation de $P$ et $Q$ avec une loi uniforme sur $[0, 1]$, puis de 1070 apr\u00e8s une it\u00e9ration et de 2893 apr\u00e8s deux it\u00e9rations. Le probl\u00e8me provient vraisemblablement de la mise \u00e0 jour de $P$ et $Q$ car la m\u00e9thode est diff\u00e9rente de celle pr\u00e9sent\u00e9e en Python. De plus l'impl\u00e9mentation en Pig ne donne pas les r\u00e9sultats escompt\u00e9s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons alors test\u00e9 une autre m\u00e9thode, o\u00f9 nous avons calcul\u00e9 ind\u00e9pendemment les termes $p_{ik} = p_{ik}(1-\\lambda\\gamma) + \n",
        "\\gamma e_{ij}q_{kj}$ pour $j$ variant de 1 \u00e0 $n$ et avons fait la moyenne : $p_{ik} = p_{ik}(1-\\lambda\\gamma) + \\frac{1}{n}\\sum_{j=1}^n \\gamma e_{ij}q_{kj}$. Au bout d'une it\u00e9ration, la distance entre $R$ et $PQ$ est de 349.58, au bout de deux it\u00e9rations 289.54. La m\u00e9thode est convergente, que ce soit pour un \u00e9chantillon r\u00e9duit d'utilisateurs ou pour l'ensemble de la base de donn\u00e9es (100 000 notes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En effet, nous avons lanc\u00e9 le calcul en Pig sur les donn\u00e9es initiales et en pr\u00e8s de deux heures, nous avons obtenu apr\u00e8s 3 it\u00e9rations la distance euclidienne des matrices $PQ$ successives \u00e0 la matrice $R$. Par souci de clart\u00e9 dans le code, nous n'avons pas fait figurer davantage d'it\u00e9rations sachant qu'il s'agit de copier-collers suppl\u00e9mentaires (car Pig ne g\u00e8re pas les boucles). La distance euclidienne apr\u00e8s 0, 1 et 2 vaut respectivement, pour l'ensemble de la base de donn\u00e9es 2,9.10^6, 2,6.10^6, 2,2.10^6. La distance semble converger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Impl\u00e9mentation PIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%PIG matrix_factorization2.pig\n",
        "\n",
        "----------------------------------------------------------------------------------------------------------------------\n",
        "--                                               Iteration 0\n",
        "----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "-----------------------------------------------------------------\n",
        "-- On charge les matrices R, P et Q;\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "R = LOAD '$CONTAINER/$PSEUDO/projet_DM/data_full.csv' USING PigStorage(',') AS (userID:int,movieID:int,rate:double);\n",
        "P = LOAD '$CONTAINER/$PSEUDO/projet_DM/matrix_p_full.csv' USING PigStorage(',') AS (userID:int, latent_p:int, val_p:double);\n",
        "Q = LOAD '$CONTAINER/$PSEUDO/projet_DM/matrix_q_full.csv' USING PigStorage(',') AS (movieID:int, latent_q:int, val_q:double);\n",
        "\n",
        "--DUMP P ;\n",
        "--DUMP Q ;\n",
        "\n",
        "-----------------------------------------------------------------\n",
        "-- On calcule le produit matriciel entre P et Q\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "-- La commande suivant joint P et Q \n",
        "P_and_Q = JOIN P BY latent_p, Q BY latent_q ;\n",
        "\n",
        "-- La commande suivante calcule tous les pik*qkj ou i=userID et j=movieID\n",
        "P_x_Q = FOREACH P_and_Q GENERATE userID, movieID, latent_p, val_p*val_q AS produit ;\n",
        "\n",
        "-- Ici on groupe tous les termes pik*qkj avec le meme couple(i,j) pour pouvoir sommer sur les k variables latentes\n",
        "grouped_P_x_Q = GROUP P_x_Q by (userID, movieID) ;\n",
        "calcul_PQ = FOREACH grouped_P_x_Q GENERATE group, SUM(P_x_Q.produit) AS ps ;\n",
        "\n",
        "-- Ici on recupere la matrice PQ :(i,j, ligne pi*colonneqj)\n",
        "PQ = FOREACH calcul_PQ GENERATE FLATTEN(group) AS (userID_2, movieID_2), ps ;\n",
        "\n",
        "\n",
        "----------------------------------------------------------------\n",
        "-- On calcule lerreur  et lerreur au carre\n",
        "----------------------------------------------------------------\n",
        "\n",
        "-- La commande suivante joint les matrices R et PQ \n",
        "R_and_PQ = JOIN R BY (userID, movieID), PQ BY (userID_2, movieID_2) ;\n",
        "\n",
        "\n",
        "-- Dans cette matrice on calcule lerreur au carre faite sur chaque coefficient de R \n",
        "E = FOREACH R_and_PQ GENERATE userID_2, movieID_2, (rate-ps) AS error, (rate-ps)*(rate-ps) AS error_sq ;\n",
        "\n",
        "-- syntaxe pour sommer = group all au lieu de group by\n",
        "\n",
        "resultat_group = GROUP E ALL ;\n",
        "resultat = FOREACH resultat_group GENERATE SUM(E.error_sq) ;\n",
        "DUMP resultat ;\n",
        "--STORE resultat into '$CONTAINER/$PSEUDO/projet_DM/resultat_iteration_0' using PIGStorage(',','-schema') ; \n",
        "\n",
        "----------------------------------------------------------------------------------------------------------------------\n",
        "--                                               Iteration 1\n",
        "----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "-----------------------------------------------------------------\n",
        "-- On met a jour P et Q\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "-- Tout dabord on joint les matrices E et P\n",
        "E_and_P = JOIN E BY userID_2, P BY userID ;\n",
        "E_and_P_bis = FOREACH E_and_P GENERATE userID, movieID_2, latent_p, error,  val_p ;\n",
        "\n",
        "-- On joint ensuite le resultat avec Q\n",
        "E_and_P_and_Q = JOIN E_and_P_bis BY (movieID_2, latent_p), Q BY (movieID, latent_q) ;\n",
        "\n",
        "\n",
        "-------------- Mise a jour de P et Q\n",
        "\n",
        "-- On calcule la matrice des gamma*e_ij*q_kj (qui vont servir a la mise a jour des p_ik) et des p_ik\n",
        "P_update1 = FOREACH E_and_P_and_Q GENERATE userID, movieID, latent_p, error, (val_p*(1-$lamb*$gamma)+$gamma*error*val_q) AS val_p, val_q; \n",
        "Q_update1 = FOREACH P_update1 GENERATE userID, movieID, latent_p AS latent_q, error, val_p, (val_q*(1-$lamb*$gamma)+$gamma*error*val_p) AS val_q ; \n",
        "\n",
        "P_group = GROUP P_update1 by (userID, latent_p) ;\n",
        "P_new = FOREACH P_group GENERATE group, AVG(P_update1.val_p) AS val_p ;\n",
        "P = FOREACH P_new GENERATE FLATTEN(group) AS (userID, latent_p), val_p ;\n",
        "--STORE P into '$CONTAINER/$PSEUDO/projet_DM/matrix_p_1' using PIGStorage(',','-schema') ; \n",
        "\n",
        "\n",
        "-- Idem pour Q\n",
        "Q_group = GROUP Q_update1 by (movieID, latent_q) ;\n",
        "Q_new = FOREACH Q_group GENERATE group, AVG(Q_update1.val_q) AS val_q ;\n",
        "Q = FOREACH Q_new GENERATE FLATTEN(group) AS (movieID, latent_q), val_q ;\n",
        "--STORE Q into '$CONTAINER/$PSEUDO/projet_DM/matrix_q_1' using PIGStorage(',','-schema') ; \n",
        "\n",
        "\n",
        "-----------------------------------------------------------------\n",
        "-- On calcule le produit matriciel entre P et Q\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "-- La commande suivant joint P et Q \n",
        "P_and_Q = JOIN P BY latent_p, Q BY latent_q ;\n",
        "\n",
        "-- La commande suivante calcule tous les pik*qkj ou i=userID et j=movieID\n",
        "P_x_Q = FOREACH P_and_Q GENERATE userID, movieID, latent_p, val_p*val_q AS produit ;\n",
        "\n",
        "-- Ici on groupe tous les termes pik*qkj avec le meme couple(i,j) pour pouvoir sommer sur les k variables latentes\n",
        "grouped_P_x_Q = GROUP P_x_Q by (userID, movieID) ;\n",
        "calcul_PQ = FOREACH grouped_P_x_Q GENERATE group, SUM(P_x_Q.produit) AS ps ;\n",
        "\n",
        "-- Ici on recupere la matrice PQ :(i,j, ligne pi*colonneqj)\n",
        "PQ = FOREACH calcul_PQ GENERATE FLATTEN(group) AS (userID_2, movieID_2), ps ;\n",
        "\n",
        "\n",
        "----------------------------------------------------------------\n",
        "-- On calcule lerreur  et lerreur au carre\n",
        "----------------------------------------------------------------\n",
        "\n",
        "-- La commande suivante joint les matrices R et PQ \n",
        "R_and_PQ = JOIN R BY (userID, movieID), PQ BY (userID_2, movieID_2) ;\n",
        "\n",
        "-- Dans cette matrice on calcule lerreur au carre faite sur chaque coefficient de R \n",
        "E = FOREACH R_and_PQ GENERATE userID_2, movieID_2, (rate-ps) AS error, (rate-ps)*(rate-ps) AS error_sq ;\n",
        "\n",
        "\n",
        "-- syntaxe pour sommer = group all au lieu de group by\n",
        "\n",
        "resultat_group = GROUP E ALL ;\n",
        "resultat = FOREACH resultat_group GENERATE SUM(E.error_sq) ;\n",
        "DUMP resultat ;\n",
        "--STORE resultat into '$CONTAINER/$PSEUDO/projet_DM/resultat_iteration_1' using PIGStorage(',','-schema') ; \n",
        "\n",
        "\n",
        "----------------------------------------------------------------------------------------------------------------------\n",
        "--                                               Iteration 2\n",
        "----------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "-----------------------------------------------------------------\n",
        "-- On met a jour P et Q\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "-- Tout dabord on joint les matrices E et P\n",
        "E_and_P = JOIN E BY userID_2, P BY userID ;\n",
        "E_and_P_bis = FOREACH E_and_P GENERATE userID, movieID_2, latent_p, error,  val_p ;\n",
        "\n",
        "-- On joint ensuite le resultat avec Q\n",
        "E_and_P_and_Q = JOIN E_and_P_bis BY (movieID_2, latent_p), Q BY (movieID, latent_q) ;\n",
        "\n",
        "\n",
        "-------------- Mise a jour de P et Q\n",
        "\n",
        "-- On calcule la matrice des gamma*e_ij*q_kj (qui vont servir a la mise a jour des p_ik) et des p_ik\n",
        "P_update1 = FOREACH E_and_P_and_Q GENERATE userID, movieID, latent_p, error, (val_p*(1-$lamb*$gamma)+$gamma*error*val_q) AS val_p, val_q; \n",
        "Q_update1 = FOREACH P_update1 GENERATE userID, movieID, latent_p AS latent_q, error, val_p, (val_q*(1-$lamb*$gamma)+$gamma*error*val_p) AS val_q ; \n",
        "\n",
        "P_group = GROUP P_update1 by (userID, latent_p) ;\n",
        "P_new = FOREACH P_group GENERATE group, AVG(P_update1.val_p) AS val_p ;\n",
        "P = FOREACH P_new GENERATE FLATTEN(group) AS (userID, latent_p), val_p ;\n",
        "--STORE P into '$CONTAINER/$PSEUDO/projet_DM/matrix_p_2' using PIGStorage(',','-schema') ; \n",
        "\n",
        "-- Idem pour Q\n",
        "Q_group = GROUP Q_update1 by (movieID, latent_q) ;\n",
        "Q_new = FOREACH Q_group GENERATE group, AVG(Q_update1.val_q) AS val_q ;\n",
        "Q = FOREACH Q_new GENERATE FLATTEN(group) AS (movieID, latent_q), val_q ;\n",
        "--STORE Q into '$CONTAINER/$PSEUDO/projet_DM/matrix_q_2' using PIGStorage(',','-schema') ; \n",
        "\n",
        "-----------------------------------------------------------------\n",
        "-- On calcule le produit matriciel entre P et Q\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "-- La commande suivant joint P et Q \n",
        "P_and_Q = JOIN P BY latent_p, Q BY latent_q ;\n",
        "\n",
        "-- La commande suivante calcule tous les pik*qkj ou i=userID et j=movieID\n",
        "P_x_Q = FOREACH P_and_Q GENERATE userID, movieID, latent_p, val_p*val_q AS produit ;\n",
        "\n",
        "-- Ici on groupe tous les termes pik*qkj avec le meme couple(i,j) pour pouvoir sommer sur les k variables latentes\n",
        "grouped_P_x_Q = GROUP P_x_Q by (userID, movieID) ;\n",
        "calcul_PQ = FOREACH grouped_P_x_Q GENERATE group, SUM(P_x_Q.produit) AS ps ;\n",
        "\n",
        "-- Ici on recupere la matrice PQ :(i,j, ligne pi*colonneqj)\n",
        "PQ = FOREACH calcul_PQ GENERATE FLATTEN(group) AS (userID_2, movieID_2), ps ;\n",
        "\n",
        "\n",
        "----------------------------------------------------------------\n",
        "-- On calcule lerreur  et lerreur au carre\n",
        "----------------------------------------------------------------\n",
        "\n",
        "-- La commande suivante joint les matrices R et PQ \n",
        "R_and_PQ = JOIN R BY (userID, movieID), PQ BY (userID_2, movieID_2) ;\n",
        "\n",
        "-- Dans cette matrice on calcule lerreur au carre faite sur chaque coefficient de R \n",
        "E = FOREACH R_and_PQ GENERATE userID_2, movieID_2, (rate-ps) AS error, (rate-ps)*(rate-ps) AS error_sq ;\n",
        "\n",
        "\n",
        "-- syntaxe pour sommer = group all au lieu de group by\n",
        "\n",
        "resultat_group = GROUP E ALL ;\n",
        "resultat = FOREACH resultat_group GENERATE SUM(E.error_sq) ;\n",
        "DUMP resultat ;\n",
        "--STORE resultat into '$CONTAINER/$PSEUDO/projet_DM/resultat_iteration_2' using PIGStorage(',','-schema') ; \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'job_1435385350894_0101'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.pig_submit(bs, \n",
        "                  client.account_name, \n",
        "                  \"matrix_factorization2.pig\", \n",
        "                  params = dict(gamma=\"0.02\", lamb=\"0.02\"), \n",
        "                  stop_on_failure=True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('job_1435385350894_0101', '21% complete', False)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "st = %hd_job_status job_1435385350894_0101\n",
        "st[\"id\"],st[\"percentComplete\"],st[\"status\"][\"jobComplete\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre>\n",
              "\n",
              "</pre><br />"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%tail_stderr job_1435385350894_0101 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%blob_downmerge /$PSEUDO/projet_DM/matrix_p_1 matrix_p_1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%blob_downmerge /$PSEUDO/projet_DM/matrix_p_2 matrix_p_2.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%blob_downmerge /$PSEUDO/projet_DM/matrix_q_1 matrix_q_1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%blob_downmerge /$PSEUDO/projet_DM/matrix_q_2 matrix_q_2.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import matrix_coo\n",
        "\n",
        "matrix_p_1 = open(\"matrix_p_1.csv\",\"r\").read()\n",
        "matrix_p_2 = open(\"matrix_p_2.csv\",\"r\").read()\n",
        "matrix_q_1 = open(\"matrix_q_1.csv\",\"r\").read()\n",
        "matrix_q_2 = open(\"matrix_q_2.csv\",\"r\").read()\n",
        "\n",
        "matrix_p_1 = matrix_coo(matrix_p_1).toarray()\n",
        "matrix_p_2 = matrix_coo(matrix_p_2).toarray()\n",
        "matrix_q_1 = matrix_coo(matrix_q_1).toarray()\n",
        "matrix_q_2 = matrix_coo(matrix_q_2).toarray()\n",
        "\n",
        "#mettre R, P, Q sous forme \"normale\" (depuis sparse)\n",
        "\n",
        "\n",
        "PQ_1 = np.dot(matrix_p_1, matrix_q_1.T)\n",
        "PQ_2 = np.dot(matrix_p_2, matrix_q_2.T)\n",
        "\n",
        "#Erreurs au carre\n",
        "print(np.sum((R-PQ_1)**2))\n",
        "print(np.sum((R-PQ_2)**2))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}