{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Web-Scraping\n",
        "\n",
        "Sous ce nom se cache une pratique tr\u00e8s utile pour toute personne souhaitant travailler sur des informations disponibles en ligne, mais n'existant pas forc\u00e9ment sous la forme d'un tableau Excel ...\n",
        "\n",
        "Le webscraping est une technique d'extraction du contenu des sites internet, via un programme informatique : nous allons aujourd'hui vous pr\u00e9senter comme cr\u00e9er et ex\u00e9cuter ces robots afin de recup\u00e9rer rapidement des informations utiles \u00e0 vos projets actuels ou futurs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n) {\n",
              "        a += \"    \";\n",
              "    }\n",
              "    return a;\n",
              "}\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    for (i = 0; i <= llast; i++) {\n",
              "        tags.push(\"h\" + i);\n",
              "    }\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null){\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\")\n",
              "        }\n",
              "\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += \"</ul>\\n\";\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2) + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<li><a href=\"#__HREF__\">__TITLE__</a></li>';\n",
              "    var send = \"\";\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Un d\u00e9tour par le Web : comment fonctionne un site ?\n",
        "\n",
        "M\u00eame si nous n'allons pas aujourd'hui faire un cours de web, il vous faut n\u00e9anmoins certaines bases pour comprendre comment un site internet fonctionne et comment sont structur\u00e9es les informations sur une page.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Un site Web est un ensemble de pages cod\u00e9es en HTML qui permet de d\u00e9crire \u00e0 la fois le contenu et la forme d'une page Web.\n",
        "\n",
        "###  HTML \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Les balises\n",
        "\n",
        "\n",
        "Sur une page web, vous trouverez toujours \u00e0 coup s\u00fbr des \u00e9l\u00e9ments comme < head>, < title>, etc. Il  s'agit des codes qui vous permettent de structurer le contenu d'une page HTML et qui s'appellent des balises. \n",
        "\n",
        "Citons, par exemple, les balises < p>, < h1>, < h2>, < h3>, < strong> ou < em>.\n",
        "\n",
        "Le symbole < > est une balise : il sert \u00e0 indiquer le d\u00e9but d'une partie. Le symbole <\\ > indique la fin de cette partie.\n",
        "\n",
        "La plupart des balises vont par paires, avec une \u00abbalise ouvrante\u00bb et une \u00abbalise fermante\u00bb. (par exemple < p> et < /p>)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Exemple : les balise des tableaux\n",
        "\n",
        "$$\n",
        "\\begin{array}{rr} \\hline\n",
        "Balise  & \\text{Description} \\\\ \\hline\n",
        "< table> & \\text{Tableau} \\\\\n",
        "< caption>& \\text{Titre du tableau} \\\\\n",
        "< tr> & \\text{Ligne de tableau} \\\\\n",
        "< th> & \\text{Cellule d'en-t\u00eate}\\\\\n",
        "< td> & \\text{Cellule} \\\\\n",
        "< thead> & \\text{Section de l'en-t\u00eate du tableau} \\\\\n",
        "< tbody> & \\text{Section du corps du tableau} \\\\\n",
        "< tfoot> & \\text{Section du pied du tableau} \\\\\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Application : un tableau en HTML\n",
        "\n",
        "Le code HTML du tableau suivant"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "<table>\n",
        "   <tr>\n",
        "      <th>Pr\u00e9nom</th>\n",
        "      <th>Nom</th>\n",
        "      <th>Profession</th>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Mike</td>\n",
        "      <td>Stuntman</td>\n",
        "      <td>Cascadeur</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Mister</td>\n",
        "      <td>Pink</td>\n",
        "      <td>Gangster</td>\n",
        "   </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Donnera dans le navigateur\n",
        "\n",
        "$$\n",
        "\\begin{array}{rrr}\n",
        "Pr\u00e9nom\t& Mike\t& Mister  \\\\\n",
        "Nom\t& Stuntman\t& Pink \\\\\n",
        "Profession &\tCascadeur\t& Gangster \\\\\n",
        "\\end{array}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Parent et enfant\n",
        "\n",
        "Dans le cadre du langage HTML, les termes de parents (parent) et enfants (child) servent \u00e0 d\u00e9signer des \u00e9lements embo\u00eet\u00e9s les uns dans les autres.\n",
        "\n",
        "Dans la construction suivante, par exemple :"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "< div> \n",
        "    < p>\n",
        "       bla,bla\n",
        "    < /p>\n",
        "< /div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On dira que l'\u00e9l\u00e9ment < div> est le parent de l'\u00e9l\u00e9ment < p> tandis que l'\u00e9l\u00e9ment < p> est l'enfant de l'\u00e9l\u00e9ment < div>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----------\n",
        "\n",
        "Mais pourquoi apprendre \u00e7a pour scraper me direz-vous ?\n",
        "\n",
        "Pour bien r\u00e9cup\u00e9rer les informations d'un site internet, il faut pouvoir comprendre sa structure et donc son code HTML. Les fonctions python qui servent au scrapping sont principalement construites pour vous permettre de naviguer entre les balises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "### Optionnel - CSS - le style de la page WEB\n",
        "\n",
        "Quand le bout de code html est \u00e9crit, il apaprait sous la forme d'un texte noir sur un fond blanc. Une mani\u00e8re simple de rendre la page plus belle, c'est d'y ajouter de la couleur. \n",
        "\n",
        "La feuille de style qui permet de rendre la page plus belle correspond au(x) fichier(s) CSS. \n",
        "\n",
        "Toutes les pages HTML qui font r\u00e9f\u00e9rence \u00e0 cette feuille de style externe h\u00e9riteront de toutes ses d\u00e9finitions.\n",
        "\n",
        "Nous y reviendrons plus en d\u00e9tail dans le TD sur Flask (module Python de cr\u00e9ation de site internet)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scrapper avec python\n",
        "\n",
        "Nous allons essentiellement utiliser le package BeautifulSoup4 pour ce cours, mais d'autres packages existent (Selenium, Scrapy...).\n",
        "\n",
        "BeautifulSoup sera suffisant quand vous voudrez travailler sur des pages HTML statiques, d\u00e8s que les informations que vous recherchez sont g\u00e9n\u00e9r\u00e9es via l'ex\u00e9cution de scripts Javascipt, il vous faudra passer par des outils comme Selenium.\n",
        "\n",
        "De m\u00eame, si vous ne connaissez pas l'URL, il faudra passer par un framework comme Scrapy, qui passe facilement d'une page \u00e0 une autre (\"crawl\"). Scrapy est plus complexe \u00e0 manipuler que BeautifulSoup : si vous voulez plus de d\u00e9tails, rendez-vous sur la page du tutorial https://doc.scrapy.org/en/latest/intro/tutorial.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utiliser BeautifulSoup\n",
        "\n",
        "Les packages pour scrapper des pages HTML : \n",
        "- BeautifulSoup (pip install bs4)\n",
        "- urllib "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import urllib\n",
        "import bs4\n",
        "#help(bs4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1ere page HTML\n",
        "\n",
        "On va commencer facilement, prenons une page wikipedia, par exemple celle de la Ligue 1 de football :\n",
        "\n",
        "https://fr.wikipedia.org/wiki/Championnat_de_France_de_football_2016-2017\n",
        "\n",
        "On va souhaiter r\u00e9cup\u00e9rer la liste des \u00e9quipes, ainsi que les url des pages Wikipedia de ces \u00e9quipes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"fr\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Championnat de France de football 2016-2017 \\xe2\\x80\\x94 Wikip\\xc3\\xa9dia</title>\\n<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\\\s)client-nojs(\\\\s|$)/, \"$1client-js$2\" );</script>\\n<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Championnat_de_France_de_football_2016-2017\",\"wgTitle\":\"Championnat de France de football 2016-2017\",\"wgCurRevisionId\":130352788,\"wgRevisionId\":130352788,\"wgArticleId\":9734718,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Comp\\xc3\\xa9tition sportive en cours\",\"Portail:Actualit\\xc3\\xa9/Articles li\\xc3\\xa9s\",\"Portail:Football/Articles li\\xc3\\xa9s\",\"Portail:Sport/Articles li\\xc3\\xa9s\",\"Portail:France/Articles li\\xc3\\xa9s\",\"Portail:Europe/Articles li\\xc3\\xa9s\",\"Portail:Monaco/Articles li\\xc3\\xa9s\",\"Port'\n"
          ]
        }
      ],
      "source": [
        "# Etape 1 : se connecter \u00e0 la page wikipedia et obtenir le code source\n",
        "\n",
        "url_ligue_1 = \"https://fr.wikipedia.org/wiki/Championnat_de_France_de_football_2016-2017\"\n",
        "    \n",
        "from urllib import request\n",
        "\n",
        "request_text = request.urlopen(url_ligue_1).read()\n",
        "print(request_text[:1000])    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Etape 2 : utiliser le package BeautifulSoup\n",
        "# qui \"comprend\" les balises contenues dans la chaine de caract\u00e8res renvoy\u00e9e par la fonction request\n",
        "\n",
        "page = bs4.BeautifulSoup(request_text, \"lxml\")\n",
        "\n",
        "#print(page)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si on print l'objet, page cr\u00e9\u00e9e avec BeautifulSoup, on voit que ce n'est plus une chaine de caract\u00e8res mais bien une page HTML avec des balises. On peut \u00e0 pr\u00e9senter chercher des \u00e9lements \u00e0 l'int\u00e9rieur de ces balises.\n",
        "\n",
        "\n",
        "par exemple, si on veut connaire le titre de la page, on utilise la m\u00e9thode .find et on lui demande \"title\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<title>Championnat de France de football 2016-2017 \u2014 Wikip\u00e9dia</title>\n"
          ]
        }
      ],
      "source": [
        "print(page.find(\"title\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "la methode .find ne renvoie que la premi\u00e8re occurence de l'\u00e9l\u00e9ment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<table>\n",
            "<caption style=\"background:#99cc99; color: #000000;\">G\u00e9n\u00e9ralit\u00e9s</caption>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Sport</th>\n",
            "<td><a href=\"/wiki/Football\" title=\"Football\">Football</a></td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Organisateur(s)</th>\n",
            "<td><a href=\"/wiki/Ligue_de_football_professionnel\" title=\"Ligue de football professionnel\">LFP</a></td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">\u00c9dition</th>\n",
            "<td><abbr class=\"abbr\" title=\"Soixante-dix-neuvi\u00e8me (septante-neuvi\u00e8me)\">79<sup>e</sup></abbr></td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Lieu(x)</th>\n",
            "<td><span class=\"datasortkey\" data-sort-value=\"France\"><span class=\"flagicon\"><a class=\"image\" href=\"/wiki/Fichier:Flag_of_France.svg\" title=\"Drapeau de la France\"><img alt=\"Drapeau de la France\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"900\" height=\"13\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/20px-Flag_of_France.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/30px-Flag_of_France.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Flag_of_France.svg/40px-Flag_of_France.svg.png 2x\" width=\"20\"/></a>\u00a0</span><a href=\"/wiki/France\" title=\"France\">France</a></span> et <span class=\"datasortkey\" data-sort-value=\"Monaco\"><span class=\"flagicon\"><a class=\"image\" href=\"/wiki/Fichier:Flag_of_Monaco.svg\" title=\"Drapeau de Monaco\"><img alt=\"Drapeau de Monaco\" class=\"thumbborder\" data-file-height=\"600\" data-file-width=\"750\" height=\"16\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/20px-Flag_of_Monaco.svg.png\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/30px-Flag_of_Monaco.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Flag_of_Monaco.svg/40px-Flag_of_Monaco.svg.png 2x\" width=\"20\"/></a>\u00a0</span><a href=\"/wiki/Monaco\" title=\"Monaco\">Monaco</a></span></td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Date</th>\n",
            "<td>du <time class=\"nowrap date-lien\" datetime=\"2016-08-12\"><a href=\"/wiki/12_ao%C3%BBt\" title=\"12 ao\u00fbt\">12</a> <a href=\"/wiki/Ao%C3%BBt_2016\" title=\"Ao\u00fbt 2016\">ao\u00fbt</a> <a href=\"/wiki/2016\" title=\"2016\">2016</a></time><br/>\n",
            "au <time class=\"nowrap date-lien\" datetime=\"2017-05-20\"><a href=\"/wiki/20_mai\" title=\"20 mai\">20</a> <a href=\"/wiki/Mai_2017\" title=\"Mai 2017\">mai</a> <a href=\"/wiki/2017\" title=\"2017\">2017</a></time></td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Participants</th>\n",
            "<td>20 \u00e9quipes</td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Site web officiel</th>\n",
            "<td>\n",
            "<p class=\"plainlinks\"><a class=\"external text\" href=\"http://www.lfp.fr\" rel=\"nofollow\">Site officiel</a></p>\n",
            "</td>\n",
            "</tr>\n",
            "</table>\n"
          ]
        }
      ],
      "source": [
        "print(page.find(\"table\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---------------\n",
        "Pour trouver toutes les occurences, on utilise .findAll()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il y a 30 \u00e9l\u00e9ments dans la page qui sont des <table>\n"
          ]
        }
      ],
      "source": [
        "print(\"Il y a\", len(page.findAll(\"table\")), \"\u00e9l\u00e9ments dans la page qui sont des <table>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Le 2eme tableau de la page : Hi\u00e9rarchie \n",
            " <table>\n",
            "<caption style=\"background:#99cc99; color: #000000;\">Hi\u00e9rarchie</caption>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Hi\u00e9rarchie</th>\n",
            "<td><abbr class=\"abbr\" title=\"Premier\">1<sup>er</sup></abbr> \u00e9chelon</td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Niveau inf\u00e9rieur</th>\n",
            "<td><a href=\"/wiki/Championnat_de_France_de_football_de_Ligue_2_2016-2017\" title=\"Championnat de France de football de Ligue 2 2016-2017\">Ligue 2 2016-2017</a></td>\n",
            "</tr>\n",
            "</table>\n",
            "--------------------------------------------------------\n",
            "Le 3eme tableau de la page : Palmar\u00e8s \n",
            " <table>\n",
            "<caption style=\"background:#99cc99; color: #000000;\">Palmar\u00e8s</caption>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Tenant du titre</th>\n",
            "<td><a href=\"/wiki/Paris_Saint-Germain_Football_Club\" title=\"Paris Saint-Germain Football Club\">Paris Saint-Germain</a> (6)</td>\n",
            "</tr>\n",
            "<tr>\n",
            "<th scope=\"row\" style=\"width:10.5em;\">Promu(s) en d\u00e9but de saison</th>\n",
            "<td><a href=\"/wiki/Association_sportive_Nancy-Lorraine\" title=\"Association sportive Nancy-Lorraine\">AS Nancy-Lorraine</a><br/>\n",
            "<a href=\"/wiki/Dijon_Football_C%C3%B4te-d%27Or\" title=\"Dijon Football C\u00f4te-d'Or\">Dijon FCO</a><br/>\n",
            "<a href=\"/wiki/Football_Club_de_Metz\" title=\"Football Club de Metz\">FC Metz</a></td>\n",
            "</tr>\n",
            "</table>\n"
          ]
        }
      ],
      "source": [
        "print(\" Le 2eme tableau de la page : Hi\u00e9rarchie \\n\", page.findAll(\"table\")[1])\n",
        "print(\"--------------------------------------------------------\")\n",
        "print(\"Le 3eme tableau de la page : Palmar\u00e8s \\n\",page.findAll(\"table\")[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice guid\u00e9 : obtenir la liste des \u00e9quipes de Ligue 1\n",
        "\n",
        "La liste des \u00e9quipes est dans le tableau \"Participants\" : dans le code source, on voit que ce tableau est celui qui a class = \"DebutCarte\" \n",
        "\n",
        "On voit \u00e9galement que les balises qui encerclent les noms et les urls des clubs sont de la forme suivante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "<a href=\"url_club\" title=\"nom_club\"> Nom du club </a>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<a class=\"image\" href=\"/wiki/Fichier:France_relief_location_map.jpg\"><img alt=\"France relief location map.jpg\" data-file-height=\"1922\" data-file-width=\"2000\" height=\"288\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f7/France_relief_location_map.jpg/300px-France_relief_location_map.jpg\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/f/f7/France_relief_location_map.jpg/450px-France_relief_location_map.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f7/France_relief_location_map.jpg/600px-France_relief_location_map.jpg 2x\" width=\"300\"/></a> \n",
            "-------\n",
            "<a href=\"/wiki/Paris_Saint-Germain_Football_Club\" title=\"Paris Saint-Germain Football Club\">Paris SG</a> \n",
            "-------\n",
            "<a href=\"/wiki/Association_sportive_de_Monaco_football_club\" title=\"Association sportive de Monaco football club\">AS Monaco FC</a> \n",
            "-------\n",
            "<a href=\"/wiki/Olympique_lyonnais\" title=\"Olympique lyonnais\">Olympique lyonnais</a> \n",
            "-------\n",
            "<a href=\"/wiki/Stade_rennais_football_club\" title=\"Stade rennais football club\">Stade rennais FC</a> \n",
            "-------\n"
          ]
        }
      ],
      "source": [
        "for item in page.find('table', {'class' : 'DebutCarte'}).findAll({'a'})[0:5] : \n",
        "    print(item, \"\\n-------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On n'a pas envie de prendre le premier \u00e9l\u00e9ment qui ne correspond pas \u00e0 un club mais \u00e0 une image.\n",
        "\n",
        "Or cet \u00e9l\u00e9ment est le seul qui n'ait pas de title = \"\". \n",
        "\n",
        "Il est conseill\u00e9 d'exclure les \u00e9lements qui ne nous int\u00e9ressent pas en indiquant les \u00e9l\u00e9ments que la ligne doit avoir au lieu de les exclure en fonction de leur place dans la liste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<a href=\"/wiki/Paris_Saint-Germain_Football_Club\" title=\"Paris Saint-Germain Football Club\">Paris SG</a>\n",
            "<a href=\"/wiki/Association_sportive_de_Monaco_football_club\" title=\"Association sportive de Monaco football club\">AS Monaco FC</a>\n",
            "<a href=\"/wiki/Olympique_lyonnais\" title=\"Olympique lyonnais\">Olympique lyonnais</a>\n",
            "<a href=\"/wiki/Stade_rennais_football_club\" title=\"Stade rennais football club\">Stade rennais FC</a>\n"
          ]
        }
      ],
      "source": [
        "### condition sur la place dans la liste >>>> MAUVAIS\n",
        "for e, item in enumerate(page.find('table', {'class' : 'DebutCarte'}).findAll({'a'})[0:5]) : \n",
        "    if  e == 0: \n",
        "        pass\n",
        "    else : \n",
        "        print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<a href=\"/wiki/Paris_Saint-Germain_Football_Club\" title=\"Paris Saint-Germain Football Club\">Paris SG</a>\n",
            "<a href=\"/wiki/Association_sportive_de_Monaco_football_club\" title=\"Association sportive de Monaco football club\">AS Monaco FC</a>\n",
            "<a href=\"/wiki/Olympique_lyonnais\" title=\"Olympique lyonnais\">Olympique lyonnais</a>\n",
            "<a href=\"/wiki/Stade_rennais_football_club\" title=\"Stade rennais football club\">Stade rennais FC</a>\n"
          ]
        }
      ],
      "source": [
        "#### condition sur les \u00e9l\u00e9ments que doit avoir la ligne >>>> BIEN \n",
        "for item in page.find('table', {'class' : 'DebutCarte'}).findAll({'a'})[0:5] : \n",
        "    if item.get(\"title\") :\n",
        "        print(item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enfin la derni\u00e8re \u00e9tape, consiste \u00e0 obtenir les informations souhait\u00e9es, c'est \u00e0 dire dans notre cas, le nom et l'url des 20 clubs. \n",
        "\n",
        "Pour cela, nous allons utiliser deux m\u00e9thodes de l'\u00e9lement item : \n",
        "- getText() qui permet d'obtenir le texte qui est sur la page web et dans la balise  < a>\n",
        "- get('xxxx') qui permet d'obtenir l'\u00e9l\u00e9ment qui est \u00e9gal \u00e0 xxxx\n",
        "\n",
        "Dans notre cas, nous allons vouloir le nom du club ainsi que l'url : on va donc utiliser __getText__ et __get(\"href\")__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/wiki/Paris_Saint-Germain_Football_Club\n",
            "Paris SG\n",
            "/wiki/Association_sportive_de_Monaco_football_club\n",
            "AS Monaco FC\n",
            "/wiki/Olympique_lyonnais\n",
            "Olympique lyonnais\n",
            "/wiki/Stade_rennais_football_club\n",
            "Stade rennais FC\n"
          ]
        }
      ],
      "source": [
        "for item in page.find('table', {'class' : 'DebutCarte'}).findAll({'a'})[0:5] : \n",
        "    if item.get(\"title\") :\n",
        "        print(item.get(\"href\"))\n",
        "        print(item.getText())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paris Saint-Germain Football Club\n",
            "Association sportive de Monaco football club\n",
            "Olympique lyonnais\n",
            "Stade rennais football club\n"
          ]
        }
      ],
      "source": [
        "# pour avoir le nom officiel, on aurait utiliser l'\u00e9l\u00e9ment <title>\n",
        "for item in page.find('table', {'class' : 'DebutCarte'}).findAll({'a'})[0:5] : \n",
        "    if item.get(\"title\") :\n",
        "        print(item.get(\"title\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "Toutes ces informations, on souhaite les conserver dans un tableau Excel pour pouvoir les r\u00e9uitiliser \u00e0 l'envie : pour cela, rien de plus simple, on va passer par pandas, parce qu'on le maitrise parfaitement \u00e0 ce stade de la formation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "\n",
        "liste_noms = []\n",
        "liste_urls = []\n",
        "\n",
        "for item in page.find('table', {'class' : 'DebutCarte'}).findAll({'a'}) : \n",
        "    if item.get(\"title\") :\n",
        "        liste_urls.append(item.get(\"href\"))\n",
        "        liste_noms.append(item.getText())\n",
        "        \n",
        "df = pandas.DataFrame.from_dict( {\"clubs\" : liste_noms, 'url' : liste_urls})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clubs</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Paris SG</td>\n",
              "      <td>/wiki/Paris_Saint-Germain_Football_Club</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS Monaco FC</td>\n",
              "      <td>/wiki/Association_sportive_de_Monaco_football_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Olympique lyonnais</td>\n",
              "      <td>/wiki/Olympique_lyonnais</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stade rennais FC</td>\n",
              "      <td>/wiki/Stade_rennais_football_club</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OGC Nice</td>\n",
              "      <td>/wiki/Olympique_gymnaste_club_Nice_C%C3%B4te_d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                clubs                                                url\n",
              "0            Paris SG            /wiki/Paris_Saint-Germain_Football_Club\n",
              "1        AS Monaco FC  /wiki/Association_sportive_de_Monaco_football_...\n",
              "2  Olympique lyonnais                           /wiki/Olympique_lyonnais\n",
              "3    Stade rennais FC                  /wiki/Stade_rennais_football_club\n",
              "4            OGC Nice  /wiki/Olympique_gymnaste_club_Nice_C%C3%B4te_d..."
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercice de web scraping avec BeautifulSoup\n",
        "\n",
        "Pour cet exercice, nous vous demandons d'obtenir 1) les informations personnelles des 721 pokemons sur le site internet http://pokemondb.net/pokedex/national\n",
        "\n",
        "Les informations que nous aimerions obtenir au final pour les pokemons sont celles contenues dans 4 tableaux :\n",
        "- Pok\u00e9dex data\n",
        "- Training\n",
        "- Breeding\n",
        "- Base stats\n",
        "\n",
        "Pour exemple :  http://pokemondb.net/pokedex/nincada\n",
        "\n",
        "2) Nous aimerions que vous r\u00e9cup\u00e9riez \u00e9galement les images de chacun des pok\u00e9mons et que vous les enregistriez dans un dossier  (indice : utilisez les modules request et shutil)\n",
        "_pour cette question ci, il faut que vous cherchiez de vous m\u00eame certains \u00e9l\u00e9ments, tout n'est pas pr\u00e9sent dans le TD_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aller sur internet avec Selenium\n",
        "\n",
        "L'avantage du package Selenium est d'obtenir des informations du site qui ne sont pas dans le code html mais qui apparaissent uniquement \u00e0 la suite de l'ex\u00e9cution de script javascript en arri\u00e8re plan. \n",
        "\n",
        "Selenium se comporte comme un utilisateur qui surfe sur internet : il clique sur des liens, il remplit des formulaires etc.\n",
        "\n",
        "\n",
        "Dans cet exemple, nous allons essayer de aller sur le site de Google Actualit\u00e9s et entrer dans la barre de recherche un sujet donn\u00e9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import selenium #pip install selenium\n",
        "# t\u00e9l\u00e9charger le chrome driver http://chromedriver.storage.googleapis.com/index.html?path=2.24/\n",
        "path_to_web_driver = \"./chromedriver\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from pyquickhelper.filehelper import download, unzip_files\n",
        "if \"win\" in sys.platform:\n",
        "    if not os.path.exists(\"chromedriver_win32.zip\"):\n",
        "        d = download(\"http://chromedriver.storage.googleapis.com/2.24/chromedriver_win32.zip\")\n",
        "    if not os.path.exists(\"chromedriver.exe\"):\n",
        "        unzip_files(\"chromedriver_win32.zip\", where_to=\".\")\n",
        "elif sys.platform.startswith(\"linux\"):\n",
        "    if not os.path.exists(\"chromedriver_linux64.zip\"):\n",
        "        d = download(\"http://chromedriver.storage.googleapis.com/2.24/chromedriver_linux64.zip\")\n",
        "    if not os.path.exists(\"chromedriver\"):\n",
        "        unzip_files(\"chromedriver_linux64.zip\", where_to=\".\")\n",
        "elif sys.platform.startswith(\"darwin\"):\n",
        "    if not os.path.exists(\"chromedriver_mac64.zip\"):\n",
        "        d = download(\"http://chromedriver.storage.googleapis.com/2.24/chromedriver_mac64.zip\")\n",
        "    if not os.path.exists(\"chromedriver\"):\n",
        "        unzip_files(\"chromedriver_mac64.zip\", where_to=\".\")        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "browser = webdriver.Chrome(path_to_web_driver)\n",
        "browser.get('https://news.google.com/')\n",
        "\n",
        "# on cherche l'endroit o\u00f9 on peut remplir un formulaire en utilisant les outils du navigateur > inspecter les \u00e9l\u00e9ments de la page\n",
        "# on voit que la barre de recherche est un \u00e9lement du code appel\u00e9 'q' comme query\n",
        "# on lui demande de chercher cet \u00e9l\u00e9ment\n",
        "search = browser.find_element_by_name('q')\n",
        "\n",
        "# on envoie \u00e0 cet endroit le mot qu'on aurait tap\u00e9 dans la barre de recherche\n",
        "search.send_keys(\"alstom\")\n",
        "\n",
        "# on appuie sur le bouton \"Entr\u00e9e\" Return en anglais\n",
        "search.send_keys(Keys.RETURN) \n",
        "\n",
        "links = browser.find_elements_by_xpath(\"//h3[@class='r _U6c']/a[@href]\")\n",
        "\n",
        "results = []\n",
        "for link in links:\n",
        "    url = link.get_attribute('href')\n",
        "    results.append(url)\n",
        "\n",
        "### on a une pause de 10 secondes pour aller voir ce qui se passe sur la page internet\n",
        "time.sleep(10)\n",
        "\n",
        "# on demande de quitter le navigateur quand tout est fini\n",
        "browser.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['http://www.lemonde.fr/les-decodeurs/article/2016/10/06/les-quatre-faiblesses-du-plan-de-sauvetage-d-alstom-belfort_5009504_4355770.html', 'https://www.contrepoints.org/2016/10/08/268222-faut-il-sauver-alstom', 'http://www.francetvinfo.fr/economie/entreprises/alstom/info-franceinfo-sauvetage-d-alstom-a-belfort-une-decision-inefficace-a-long-terme-pour-plus-de-deux-tiers-des-francais_1859457.html', 'http://www.usinenouvelle.com/article/top-flop-alstom-ariane-5-cop21-les-actus-qu-il-ne-fallait-pas-rater-cette-semaine.N448312', 'http://www.lemonde.fr/economie-francaise/video/2016/10/05/alstom-les-francais-ne-sont-pas-dupes-de-ce-bricolage_5008741_1656968.html', 'http://www.lemonde.fr/idees/article/2016/10/07/alstom-et-si-nous-manquions-de-pompidolisme_5009838_3232.html', 'http://www.lemonde.fr/economie-francaise/article/2016/10/04/a-belfort-les-salaries-d-alstom-restent-vigilants-et-prudents-apres-les-annonces-de-la-direction_5008123_1656968.html', 'http://www.lesechos.fr/industrie-services/tourisme-transport/0211358119613-alstom-un-sauvetage-ubuesque-2032387.php', 'http://www.lemonde.fr/economie/article/2016/10/05/de-belfort-a-boras_5008464_3234.html', 'http://www.leparisien.fr/economie/l-avenir-d-alstom-en-france-toujours-fragile-05-10-2016-6176303.php']\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Obtenir des informations datant de moins d'une heure sur Google News"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.google.com/search?q=alstom&hl=fr&gl=fr&authuser=0&tbm=nws&source=lnt&tbs=qdr:h&sa=X&ved=0ahUKEwi1-9fo6MrPAhXMJMAKHcjXAy4QpwUIFg\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "browser = webdriver.Chrome(path_to_web_driver)\n",
        "browser.get('https://news.google.com/')\n",
        "\n",
        "search = browser.find_element_by_name('q')\n",
        "# on envoie \u00e0 cet endroit le mot qu'on aurait tap\u00e9 dans la barre de recherche\n",
        "search.send_keys(\"alstom\")\n",
        "# on appuie sur le bouton \"Rechercher\"\n",
        "search.send_keys(Keys.RETURN) \n",
        "\n",
        "#pour obtenir le lien vers les articles d'il y a moins d'une heure : \n",
        "# on utilise ce qu'on a trouv\u00e9 dans le code source \u00e0 savoir l'url pour les articles de moins d'une heure\n",
        "\n",
        "link = browser.find_element_by_xpath(\"//li[@id='qdr_h']/a[@href]\").get_attribute('href')\n",
        "print(link)\n",
        "\n",
        "browser.get(link)\n",
        "\n",
        "links = browser.find_elements_by_xpath(\"//h3[@class='r _U6c']/a[@href]\")\n",
        "\n",
        "results = []\n",
        "for link in links:\n",
        "    url = link.get_attribute('href')\n",
        "    results.append(url)\n",
        "    \n",
        "#################################\"\n",
        "#print(results)\n",
        "#time.sleep(5)\n",
        "browser.quit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Obtenir des nouvelles sur un sujet entre deux dates donn\u00e9es"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En r\u00e9alit\u00e9, l'exemple de Google News aurait pu se passer de Selenium et \u00eatre utilis\u00e9 directement avec BeautifulSoup et les url qu'on r\u00e9ussit \u00e0 deviner de Google. \n",
        "\n",
        "Ici, on utilise l'url de Google News pour cr\u00e9er une petite fonction qui donne pour chaque ensemble de (sujet, debut d'une p\u00e9riode, fin d'une p\u00e9riode) des liens pertinents issus de la recherche Google."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from selenium import webdriver\n",
        "\n",
        "\n",
        "def get_news_specific_dates (beg_date, end_date, subject, hl = \"fr\", gl = \"fr\", tbm = \"nws\", authuser = \"0\") :\n",
        "    '''Permet d obtenir pour une requete donn\u00e9e et un intervalle temporel\n",
        "    pr\u00e9cis les 10 premiers r\u00e9sultats \n",
        "    d articles de presse parus sur le sujet'''\n",
        "    get_string = 'https://www.google.com/search?hl={}&gl={}&tbm={}&authuser={}&q={}&tbs=cdr%3A1%2Ccd_min%3A{}%2Ccd_max%3A{}&tbm={}'.format(hl,gl,tbm,authuser,subject,beg_date,end_date,tbm)\n",
        "    browser.get(get_string)\n",
        "    \n",
        "    links = browser.find_elements_by_xpath(\"//h3[@class='r _U6c']/a[@href]\")\n",
        "\n",
        "    results = []\n",
        "    for link in links:\n",
        "        url = link.get_attribute('href')\n",
        "        results.append(url)\n",
        "    browser.quit()    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "### On appelle la fonction cr\u00e9\u00e9e \u00e0 l'instant\n",
        "browser = webdriver.Chrome(path_to_web_driver)\n",
        "articles_mai_2015 = get_news_specific_dates(\"01/05/2015\",\"31/05/2015\",\"soci\u00e9t\u00e9 g\u00e9n\u00e9rale jerome kerviel\",hl=\"fr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['http://www.lemonde.fr/les-decodeurs/article/2015/05/19/affaire-kerviel-sept-ans-de-mysteres_4635986_4355770.html', 'https://www.franceinter.fr/emissions/affaires-sensibles/affaires-sensibles-26-mai-2015', 'http://www.lepoint.fr/societe/une-majorite-de-francais-a-une-bonne-image-de-jerome-kerviel-29-05-2015-1932232_23.php', 'http://www.lefigaro.fr/societes/2015/05/19/20005-20150519ARTFIG00362-l-affaire-kerviel-s-invite-encore-a-l-assemblee-de-la-societe-generale.php', 'http://www.humanite.fr/affaire-kerviel-un-scandale-detat-574812', 'https://www.mediapart.fr/journal/france/170515/le-temoignage-dune-commandante-de-police-fait-exploser-le-dossier-kerviel?onglet=full', 'http://lexpansion.lexpress.fr/actualite-economique/apres-l-affaire-kerviel-la-piste-du-scandale-d-etat_1681063.html', 'http://www.humanite.fr/affaire-kerviel-la-societe-generale-doit-changer-de-banc-574281', 'http://www.bfmtv.com/mediaplayer/video/affaire-kerviel-il-est-important-de-savoir-si-la-societe-generale-prend-en-compte-les-revelations-de-mediapart-estime-richard-amalvy-530503.html', 'http://www.cadtm.org/Les-banques-et-la-nouvelle,11665']\n"
          ]
        }
      ],
      "source": [
        "print(articles_mai_2015)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utiliser selenium pour jouer \u00e0 2048\n",
        "\n",
        "Dans cet exemple, on utilise le module pour que python appuie lui m\u00eame sur les touches du clavier afin de jouer \u00e0 2048.\n",
        "\n",
        "Note : ce bout de code ne donne pas une solution \u00e0 2048, il permet juste de voir ce qu'on peut faire avec selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score final : 1332 en 139 coups\n"
          ]
        }
      ],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "# on ouvre la page internet du jeu 2048\n",
        "\n",
        "browser = webdriver.Chrome(path_to_web_driver)\n",
        "browser.get('https://gabrielecirulli.github.io/2048/')\n",
        "\n",
        "# Ce qu'on va faire : une boucle qui r\u00e9p\u00e8te inlassablement la m\u00eame chose : haut / droite / bas / gauche\n",
        "\n",
        "# on commence par cliquer sur la page pour que les touches sachent \n",
        "browser.find_element_by_class_name('grid-container').click()\n",
        "grid = browser.find_element_by_tag_name('body')\n",
        "\n",
        "# pour savoir quels coups faire \u00e0 quel moment, on cr\u00e9e un dictionnaire\n",
        "direction = {0: Keys.UP, 1: Keys.RIGHT, 2: Keys.DOWN, 3: Keys.LEFT}\n",
        "count = 0\n",
        "\n",
        "while True:\n",
        "    try: # on v\u00e9rifie que le bouton \"Try again\" n'est pas l\u00e0 - sinon \u00e7a veut dire que le jeu est fini\n",
        "        retryButton = browser.find_element_by_link_text('Try again')\n",
        "        scoreElem = browser.find_element_by_class_name('score-container')\n",
        "        break\n",
        "    except:\n",
        "        #Do nothing.  Game is not over yet\n",
        "        pass\n",
        "    # on continue le jeu - on appuie sur la touche suivante pour le coup d'apr\u00e8s\n",
        "    count += 1\n",
        "    grid.send_keys(direction[count % 4]) \n",
        "    time.sleep(0.1)\n",
        "\n",
        "print('Score final : {} en {} coups'.format(scoreElem.text, count))    \n",
        "browser.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}